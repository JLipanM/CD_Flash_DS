{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw1ZJy3Urv0Cqczm/isfXK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Markohf/CD_Flash_DS/blob/main/C6_2_Limpieza_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Limpieza de datos\n",
        "\n",
        "Como vimos en la clase anterior \"C6.1. Renombrar y eliminar columnas\" es muy importante, antes de analizar y procesar nuestros datos para generar información de valor, limpiar nuestro dataset.\n",
        "\n",
        "Ya aprendimos algunas formas de limpieza como limpiar nuestros encabezados y eliminar columnas innecesarias. En esta clase iremos un paso más adelante.\n",
        "\n",
        "Para esta clase usaremos un dataset muy conocido en el entorno de machine learning llamado \"Titanic\". Podemos encontrar esta BBDD en Kaggle una plataforma que les servirá mucho como futuros Data Scientist.\n",
        "\n",
        "La finalidad de esta clase es poder entregar un marco para la limpieza de datos, pero es importante entender que no existe una receta perfecta para hacerlo, ya que esto depende de cada dataset en específico así como tambien la finalidad del análisis y la propia creatividad y habilidad de cada Data Scientist."
      ],
      "metadata": {
        "id": "jlV81ypfUD6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualización del dataset\n",
        "\n",
        "Lo primero es poder visualizar nuestro dataset para entender a que tipo de data nos estamos enfrentando y así decidir que datos o columnas son importantes para nuestro análisis."
      ],
      "metadata": {
        "id": "wqmoYCwFXZz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2N-3t4-T-Bi"
      },
      "outputs": [],
      "source": [
        "#Importamos pandas.\n",
        "import pandas as pd\n",
        "#Cargamos datos directamente de un link.\n",
        "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ7Xta6T-hqBFfQTUMNSVdl03z74KlyecepwOK0Y4s_zv0CG6L8NrVP8tlBsnV2tI4W_cHE5NB9cduU/pub?output=csv')\n",
        "#Dar un vistazo a nuestro dataset.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Remover duplicados\n",
        "\n",
        "Nuestro dataset puede contener datos duplicados por lo que el importante revisar si existen duplicados y si es así eliminarlos. Tener en cuenta que esto depende de cada dataset ya que podría darse el caso que alguna tabla de datos si acepte por algún motivo datos repetidos."
      ],
      "metadata": {
        "id": "dFxzZn0MXsKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#El método duplicated nos devuelve un set de booleanos donde podemos identificar datos duplicados\n",
        "df.duplicated()"
      ],
      "metadata": {
        "id": "IXkT2nFgYLTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#La idea es aligerar el trabajo operativo por lo que no sirve de mucho ver uno por uno todo el set de booleanos resultante.\n",
        "#Usaremos .sum() para ver el total de duplicados.\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "-yKHOgbPYpkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Si después de analizar estos duplicados decidimos que debemos borrarlos podemos hacerlo con .drop_duplicates().\n",
        "df = df.drop_duplicates()\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "W7iufU33ZBqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Eliminar columnas\n",
        "\n",
        "Otra tarea importante que podemos hacer es eliminar columnas inncesarias, ya sea porque no contienen información relevante o por alguna otra razón."
      ],
      "metadata": {
        "id": "yATpfQw0ZdAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#En el caso de nuestro dataset podemos ver que la columna Unnamed: 0 es irrelevante.\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "Jsy5df_yZt3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Procedemos a eliminar dicha columna usando df.drop()\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "U5A7aERiZ1dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Análisis datos en columnas"
      ],
      "metadata": {
        "id": "3FJ91FpcO5-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Con .nunique() podemos entender un poco más la naturaleza de nuestro dataframe así como tambien identificar errores.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "I42SPb8RZ84k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Por ejemplo encontramos que en sex aparecen 3 opciones.\n",
        "df[\"Sex\"].value_counts()"
      ],
      "metadata": {
        "id": "KHw9HITDPO0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisamos todas las filas con F.\n",
        "df[df[\"Sex\"] == \"F\"]"
      ],
      "metadata": {
        "id": "ub0xIQU7PbFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos cambiar un dato usando .at()\n",
        "df.at[9, 'Sex'] = 'female'\n",
        "#Revisamos\n",
        "df['Sex'][9]"
      ],
      "metadata": {
        "id": "PUkX9wl7QN6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podemos cambiar más de un dato usando .replace()\n",
        "df['Sex'] = df['Sex'].replace('F', 'female')\n",
        "#Revisamos\n",
        "df['Sex'].value_counts()"
      ],
      "metadata": {
        "id": "yGxw8TkBSELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Corrigiendo tipos de dato\n",
        "\n",
        "Los tipos de datos son muy importantes ya que determinan las operaciones que podemos hacer con nuestro dataframe y por ende los métodos que podemos usar para procesarlos y obtener información valiosa."
      ],
      "metadata": {
        "id": "_cfA4wH9SzRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisamos nuestro dataframe.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aL49MPSpUujV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisamos los tipos de dato.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "paKGxpHkUVOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#La columna SibSp debería tener dolo datos del tipo int, pero vemos que .info() lo clasifica con object.\n",
        "df['SibSp'].value_counts()"
      ],
      "metadata": {
        "id": "8c6i4c8oUnNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambiaremos el dato \"one\" por 1.\n",
        "df['SibSp'] = df['SibSp'].replace('one', 1)\n",
        "df['SibSp'].value_counts()"
      ],
      "metadata": {
        "id": "YkuKinneVEr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificamos si el tipo de dato cambió.\n",
        "df.info()"
      ],
      "metadata": {
        "id": "szZ5co-xVXJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SibSp sigue siendo de tipo object y esto puede deberse a que los numeros de dicha columna no estén como integers; sino como strings.\n",
        "df['SibSp'] = df['SibSp'].astype(int)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "jj4YBHHnVg4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos lo mismo con Age, ya que no puede ser float.\n",
        "df['Age'] = df['Age'].astype(int)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "AR5eStbGVyk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Age\" contiene datos faltantes y estos no pueden ser convertidos por lo que primero debemos tratarlos. Aprenderemos sobre esto más adelante."
      ],
      "metadata": {
        "id": "0GBOQ0f0WGL1"
      }
    }
  ]
}